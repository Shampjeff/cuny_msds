---
title: "dbplyr - Tidyverse - Data 607"
author: "Jeff Shamp"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
params:
  pwd: 
---

```{r setup, include=FALSE}
library(tidyr)
library(dplyr)
library(dbplyr)
library(ggplot2)
library(RCurl)
library(RMySQL)
```

# dbplyr - Out-Source Your Data With TidyVerse 

**dbplyr is a great tool for unloading heavy amounts of data from RStudio and onto a SQL server. dbplyr is good choice when:**
-You have a data heavy environment that is slowing down your local machine
-Your knits are taking forever
-You have many files that access the same data and you don't want to reload from csv everytime
-You are working in a group

## Set Up

dbplyr works with a SQL server to retrive data and make it available as a dataframe on your local machine. dbplyr handels the SQL queries on the back end to directly interface with the server and returns an object you can further manipulate using standard Tidyverse tools. 

I will show a simple way to create a new database and populate it with data before demostrating how to use dbplyr. 

You will need another package to access the SQL server of your choice. dbplyr works very well with standard, well-known SQL server packages. I will be using `RMySQL` and Google Cloud SQL for this example. SQLite is very popular for demostration purposes, but is not as practical in a real-world scenario. 

**Reproducability:** The set up code for the SQL database is in markdown as I only need to run it once. 

### Create a new database on your server

Before we can get to dbplyr we need data and a SQL instance to tap into. Below is a very easy set up using the `RMySQL` package. You only need to use the follow code chunk once and the DB will be there as long as you keep it on your SQL server. One of the many wonderful things about storing and accessing data this way is that you only need to create one cloud instance and R and RMySQL can handle the rest - this is far superior to using MySQL workbench or some other software on your local machine. 

```markdown
conn <-                                      # Create a connection to your SQL server
    dbConnect(
      MySQL(),
      username = "root",
      password = rstudioapi::askForPassword("Database password"),
      # For rmd on github use: rstudioapi
      # For knitting use password$pwd
      host = '34.68.193.229'
    )
dbSendQuery(conn, "CREATE DATABASE Congress_v_Trump;")  # Create a DB using a SQL query. 
```

Next, let the server know you intend to use the DB you created. If starting a new session (after creating the data), establish a connection and identify the database name. 

```{r}
conn <-                                     
    dbConnect(
      MySQL(),
      username = "root",
      password = rstudioapi::askForPassword("Database password"),
      # For rmd on github use: rstudioapi
      # For knitting use password$pwd
      host = '34.68.193.229', 
      dbname = "Congress_v_Trump"
    )
#dbSendQuery(conn, "USE Congress_v_Trump")
```

The data is stored on a `.csv` file and we can load the `.csv` as dataframe and use `RMySQL` to write that dataframe to our cloud database.

**You only need to do this once. The data will stay on your SQL server as long as you want.**

```markdown
m<-getURL(
"https://raw.githubusercontent.com/Shampjeff/cuny_msds/master/DATA_607/data/averages.csv")
df<-read.csv(text=m, header = T, stringsAsFactors = F)
dbWriteTable(conn = conn, name = "Congress_v_Trump", value = df)
```

This data is now on our SQL server and ready to be used. 


## dbplyr

If you have used any dplyr functions before you'll be very happy to know that almost everything is the same for dbplyr! I'll show a few common use-cases as well as some places where dbplyr is different form dplyr. 

### tbl()

First, you need to let dbplyr know that you are using a database by pointing to a database and table. It's one line - tell dbplyr the connection and name of the database. 

**If you use a html display for your data (DT in this case), you'll have to cast the variable assigned to `tbl()` explicitly with `as.data.frame()`**

```{r}
df<-tbl(conn, "Congress_v_Trump")

DT::datatable(as.data.frame(df),
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE,
                         paging=TRUE,
                         fixedHeader=TRUE,
                         pageLength = 5))
```

Now we are ready to use dbplyr very much like we can use dplyr!









